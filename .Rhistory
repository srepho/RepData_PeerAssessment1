nina<-read.csv("C:/Users/Stephen/Desktop/Nina.csv", header=T)
library(forcast)
library(forecast)
forecast(nina)
nina
summary(nina)
nina<-read.csv("C:/Users/Stephen/Desktop/Nina.csv", header=T)
forecast(nina)
summary(nina)
library(lubridate)
nina$Month<-as.Date(nina$Month)
nina<-read.csv("C:/Users/Stephen/Desktop/Nina.csv", header=T)
summary(nina)
nina$Month<-as.Date(nina$Month)
forecast(nina)
forecast(nina$Referrals)
plot(forecast(nina$Referrals))
hist(nina$Referrals)
library(ggplot2)
qplot(nina$Referrals)
qplot(nina)
plot(nina)
?tbs
?bts
?forecast
?tbats
tbats(nina$Referrals)
tbats(nina$Referrals, num.cores=5)
tbats(nina, num.cores=5)
ets(nina)
ets(nina$Referrals)
plot(ets(nina$Referrals))
tbats(c(1. 2, 4))
test<-c(1, 2, 4)
tbats(test)
install.packages("deldir")
install.packages(c("AppliedPredictiveModeling", "C50", "deldir", "lme4", "mice", "minqa", "party", "plotmo", "rattle", "Rcpp", "rgdal"))
train_v2 <- read.csv("F:/Loans/train_v2.csv")
View(train_v2)
test_v2 <- read.csv("F:/Loans/test_v2.csv")
View(test_v2)
train<-train_v2
test<-test_v2
pred <- train[ , ncol(train), drop = TRUE]
train <- train[-ncol(train)]
train <- train[-1]
train.attr <- data.frame(
Minimum = apply(train, 2, min, na.rm = TRUE),
Maximum = apply(train, 2, max, na.rm = TRUE),
Range = apply(train, 2, max, na.rm = TRUE) - apply(train, 2, min, na.rm = TRUE),
Mean = apply(train, 2, mean, na.rm = TRUE),
StDev =  apply(train, 2, sd, na.rm = TRUE),
CV = apply(train, 2, function(x){
if(mean(x, na.rm = TRUE) == 0){0}
else{sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)}}),
Outliers = apply(train, 2, function(x){length(boxplot(x, plot = FALSE)$out)}),
NAs = apply(train, 2, function(x){sum(is.na(x))}),
IsInteger = apply(train, 2, function(x){(all.equal(x, as.integer(x)) == TRUE) * 1}),
IsSortedAsc = apply(train, 2, function(x){(all.equal(x[!is.na(x)], sort(x, na.last = NA)) == TRUE) * 1}),
IsSortedDesc = apply(train, 2, function(x){(all.equal(x[!is.na(x)], sort(x, na.last = NA, decreasing = TRUE)) == TRUE) * 1}),
UniqueValues = apply(train, 2, function(x){length(unique(x))}),
CorToPred = apply(train, 2, function(x){cor(pred, x, use = "complete.obs")})
)
train.attr$CorToPred[is.na(train.attr$CorToPred)] <- 0
train.attr.scaled <- scale(train.attr[ , c("Range", "CV", "Outliers", "NAs", "IsInteger", "UniqueValues", "CorToPred")])
hCluster <- hclust(dist(train.attr.scaled), "ward")
plot(hCluster)
train.attr$ClusterNo <- cutree(hCluster, k = 20)
Events <- read.csv("E:/PGi/Model/Clean Data/Events.csv")
View(Events)
str(Events)
hist(Events$OPERATOR)
table(Events$OPERATOR)
order(table(Events$OPERATOR))
rank(table(Events$OPERATOR))
sort(table(Events$OPERATOR))
plot(sort(table(Events$OPERATOR)))
plot(table(Events$OPERATOR))
hist(table(Events$OPERATOR))
library(ggplot2)
qplot(sort(table(Events$OPERATOR)))
qplot(table(Events$OPERATOR))
qplot(table(Events$OPERATOR), geom_bar)
qplot(table(Events$OPERATOR), geom_histogram)
?count
Count?
)
library(reshape2)
melt(Events)
blah<-melt(Events)
blah<-melt(Events$OPERATOR)
cast(blah, ~., fun=sum)
dcast(blah, ~., fun=sum)
dcast(blah, OPERATOR~., fun=sum)
dcast(blah, blah~., fun=sum)
aggregate(blah)
aggregate(blah, fun=sum)
aggregate(blah, FUN=sum)
aggregate(blah, by=list(blah$value) FUN=sum)
aggregate(blah, by=list(blah$value), FUN=sum)
aggregate(blah, by=list(blah$value), FUN=count)
dcast(blah, blah$value~., sum)
dcast(blah, blah$value~., count)
as.data.frame(table(Events$OPERATOR))
blah<-as.data.frame(table(Events$OPERATOR))
blah
blerg<-melt(blah)
dcast(blerg, var1~., sum)
dcast(blerg, Var1~., sum)
install.packages(c("cairoDevice", "caret", "denstrip", "doParallel", "doSNOW", "dynlm", "maptools", "pROC", "RcppArmadillo", "rFerns", "RGtk2", "spatstat", "testthat"))
library(C50)
data(churn)
str(churnTrain)
library(caret)
install.packages("caret")
library(caret)
set.seed(1)
?YeoJohnson
str(churnTest)
forGBM<-churnTrain
forGBM$churn<-ifelse(forGBM$churn=="yes", 1, 0)
gbmTune<-train(x=churnTrain[,predictors], y=churnTrain$churn, method="gbm")
gbmTune<-train(churn~., data=churnTrain, method="gbm", verbose=F)
ctrl<-trainControl(method="repeatedcv", repeats=5, classProbs=T, summaryFunction=twoClassSummary)
gbmTune<-train(churn~., data=churnTrain, method="gbm", verbose=F, metric="ROC", trControl=ctrl)
ctrl<-trainControl(method="repeatedcv", repeats=5, classProbs=T, summaryFunction=twoClassSummary)
grid<-expand.grid(.interaction.depth=seq(1, 7, by=2), .n.trees=seq(100, 1000, by=50), .shrinkage=c(0.01, 0.1))
gbmTune<-train(churn~., data=churnTrain, method="gbm", verbose=F, metric="ROC", trControl=ctrl)
gbmTune
gbmTune$modelInfo
gbmTune$results
gbmTune
ggplot(gbmTune)
ggplot(gbmTune) + theme(legend.position="top")
gbmTune$results
gbmTune$bestTune
gbmTune$modelInfo
gbmTune$modelType
gbmTune$perfNames
gbmProb<-predict(gbmTune, churnTest, type="prob")
confusionMatrix(gbmPred, churnTest$churn)
gbmPred<-predict(gbmTune, churnTest)
confusionMatrix(gbmPred, churnTest$churn)
install.packages(c("Hmisc", "plyr", "spam"))
install.packages(c("doSNOW", "lava", "lme4", "plotrix", "Rcpp"))
install.packages("Metrics")
install.packages("dplyr")
install.packages("e1071")
library(kernlab)
data(iris)
kpc<-kpca(iris$Species~., kernel="rbfdot")
library(dplyr)
blah<-select(iris, -Species)
kpc<-kpca(~., data=blah kernel="rbfdot")
kpc<-kpca(~., data=blah, kernel="rbfdot")
pcv(kpc)
plot(kpc)
screeplotkpc
str(kpc)
plot(pcv)
plot(rotated)
plot(eig)
screeplot(pcv(kpc))
boo<-pcv(kpc)
screeplot(boo
)
plot(pcv(kpc))
plot(rotated(kpc))
library(rTensor)
install.packages("rTensor")
library(rTensor)
mpca(blah)
mpca(blah, ranks=NULL)
mpca(blah, ranks=NULL, max_iter=25)
mpca(blah, ranks=3)
princomp(blah)
foo<-princomp(blah)
plot(foo)
screeplot(foo)
install.packages("effects")
install.packages("twang")
install.packages(c("forecast", "partykit", "rFerns", "rgeos", "rpart", "RWeka"))
Budget <- read.csv("F:/Cyntia/Job/Job/Budget.csv")
View(Budget)
x<-4
class(x)
x<-c(4, "a", TRUE)
class(x)
x <- list(2, "a", "b", TRUE)
x[[2]]
x <- c(17, 14, 4, 5, 13, 12, 10)
x[x >= 11] <- 4
x
x <- list(2, "a", "b", TRUE)
foo<-x[[2]]
foo
class(foo)
hw1_data <- read.csv("C:/Users/Stephen/Desktop/hw1_data.csv")
View(hw1_data)
blah<-hw1_data
head(blah, 2)
nrows(blah)
nrow(blah)
tail(blah, 2)
blah$Ozone[47]
summary(blah$Ozone)
library(dplyr)
foo<-filter(blah, Ozone>31 & Temp >90)
summary(foo)
foo<-filter(blah, Month==6)
summary(foo)
foo<-filter(blah, Month==5)
summary(foo)
?download.file
gcd<-download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv )
gcd<-download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv)
gcd<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
gcd<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", gcd.csv)
gcd<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "gcd.csv")
gcd <- read.csv("~/GitHub/Coursera/gcd.csv")
View(gcd)
gcd %.%
filter(Val=24) %.%
count(n)
gcd %.%
filter(Val==24) %.%
count(n)
gcd %.%
filter(VAL==24) %.%
count(n)
gcd %.%
filter(VAL==24) %.%
count=n()
gcd %.%
filter(VAL==24) %.%
summarise(count=n())
summary(gcd$FES)
?read.csv
NGAP<-read.csv("C:/Users/Stephen/Desktop", skip=8, nrows=5)
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=8, nrows=5)
View(NGAP)
foo<-NGAP[,7:14]
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=8, nrows=5, header=T)
foo<-NGAP[,7:14]
View(foo)
foo<-NGAP[7:14,]
View(foo)
View(NGAP)
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=8, nrows=5)
View(NGAP)
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=18, nrows=5, col.names=18)
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=18, nrows=5)
View(NGAP)
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=17, nrows=5)
View(NGAP)
foo<-NGAP[, 7:15]
View(foo)
dat<-foo
sum(dat$Zip*dat$Ext,na.rm=T)
install.packages("xlsx")
install.packages(c("BH", "foreach", "hts", "iterators", "mvtnorm", "rTensor", "sp"))
library(dplyr)
install.packages(c("dplyr", "forecast", "caret", "stringr", "lubridate"))
install.packages(c("AppliedPredictiveModeling", "hts"))
install.packages("BH")
install.packages(c('Rcompression', 'XML'))
install.packages(c('ROOXML', 'RExcelXML'), repos = 'http://www.omegahat.org/R', type = 'source')
install.packages(c("memoise", "reshape2", "scales"))
install.packages(c("car", "evaluate"))
install.packages("RcppArmadillo")
install.packages(c("CORElearn", "forecast", "markdown"))
install.packages(c("dplyr", "ggplot2"))
SoOScores <- read.delim("C:/Users/Stephen/Desktop/SoOScores.tsv")
View(SoOScores)
SO<-SoOScores
library(stringr)
install.packages("caret")
install.packages(c("caret", "mapdata", "maps", "maptools", "RcppArmadillo"))
install.packages(c("hts", "rjson"))
library(lattice)
?xyplot
?trellis
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?lpoints
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
p
?trellis.par.set
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
library(ggplot2)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
library(caret)
?createDataPartition
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
library(hmisc)
install.packages("Hmisc")
library(Hmisc)
?cut
?cut2
cut2(concrete)
cut2(training)
library(ggplot2)
plot(training)
plot(training$CompressiveStrength~.)
plot(training$CompressiveStrength~., data=training)
View(training)
ggplot(training, aes(y=CompressiveStrength, x=row.names))+geom_dotplot()
ggplot(concrete, aes(y=CompressiveStrength, x=row.names))+geom_dotplot()
concrete$number<-1:1030
View(concrete)
ggplot(concrete, aes(y=CompressiveStrength, x=number))+geom_dotplot()
ggplot(concrete, aes(y=CompressiveStrength, x=number))+geom_point()
ggplot(training, aes(y=CompressiveStrength, x=row.names))+geom_point()
training$numb<-1:774
ggplot(training, aes(y=CompressiveStrength, x=numb))+geom_point()
ggplot(training, aes(y=FlyAsh, x=numb))+geom_point()
ggplot(training, aes(y=CompressiveStrength, x=numb, color=FlyAsh))+geom_point()
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
log(0.02)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
library(dplyr)
library(stringr)
foo<-colnames(training)
boo<-str_extract_all(foo, "^IL")
boo
boo<-str_detect(foo, "^IL")
zoot<-training[boo]
?preProcess
res<-preProcess(zoot, method=("pca"), thresh=0.8)
ans<-predict(res, training)
ans<-predict(res, zoot)
head(anz)
head(ans)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainnonpca<-training[boo]
trainpca<-training[boo]
trainnonpca$diagnosis<-training$diagnosis
trainpca$diagnosis<-training$diagnosis
pcad<-train(trainpca$diagnosis~., method="glm", preProcess=c("pca", thresh=0.8))
pcad<-train(trainpca$diagnosis~., data=trainpca, method="glm", preProcess=c("pca", thresh=0.8))
?preProcess
?train
pcad<-train(trainpca$diagnosis~., data=trainpca, method="glm", preProcess=c(method="pca", thresh=0.8))
pcad<-train(trainpca$diagnosis~., data=trainpca, method="glm", preProcess=(method="pca", thresh=0.8))
trainpca$diagnosis<-NULL
pcamodel<-preProcess(trainpca, method=("pca"), thresh=0.8)
trainpca<-predict(pcamodel, trainpca)
trainpca$diagnosis<-training$diagnosis
pcamodel<-train(trainpca$diagnosis~., data=trainpca, method="glm")
install.packages("e1071")
pcamodel<-train(trainpca$diagnosis~., data=trainpca, method="glm")
nonpcamodel<-train(trainnonpca$diagnosis~., method="glm")
nonpcamodel<-train(trainnonpca$diagnosis~., data=trainnonpca, method="glm")
nonpcamodel
pcamodel
?predict.train
testnonpca<-training[boo]
extractPrediction(nonpcamodel, testX=testnonpca)
nonpca<-predict(nonpcamodel, newdata=testnonpca)
sqrt(sum((nonpca-training$diagnosis)^2))
head(nonpca)
setwd("C:/Users/Stephen/Desktop/Q2")
write.csv(nonpca, "nonpca.csv", row.names=F)
write.csv(testing, "test.csv", row.names=F)
testnonpca<-testing[boo]
nonpca<-predict(nonpcamodel, newdata=testnonpca)
write.csv(nonpca, "nonpca.csv", row.names=F)
setwd("E:/Coursera/ReprodResearch")
library(dplyr)
library(stringr)
library(reshape2)
library(mice)
library(lattice)
activity<-read.csv("activity.csv", header=T)
dly_steps<-select(activity, date, steps)
daily<-melt(dly_steps)
ds<-dcast(daily, date~., fun.aggregate=sum)
colnames(ds)[2]<-"steps"
hist(ds$steps)
install.packages("mice")
imp<-mice(activity)
library(mice)
imp<-mice(activity)
impactivity<-complete(imp)
impdly_steps<-select(impactivity, date, steps)
impdaily<-melt(impdly_steps)
impds<-dcast(impdaily, date~., fun.aggregate=sum)
colnames(impds)[2]<-"steps"
hist(impds$steps)
as.integer(mean(impds$steps))
median(impds$steps)
setwd("E:/Github Stuff/RepData_PeerAssessment1")
